{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly Report\n",
    "- Team members: 21700365 Son Juchan, 21700411 Ahn Dongsu, 22000176 Kim Jimin\n",
    "- Meeting Date: 2023.05.25\n",
    "- Project Name: Big Data Capstone Design\n",
    "- Project Goal: Capstone Topic Selection and Proposal Writing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly plan\n",
    "\n",
    "| Week    | Schedule        | Note                      |\n",
    "|---------|-----------------|---------------------------|\n",
    "| Week 9  | 2023.04.27<br>Topic selection and clarification | Presentation of individual interest topics |\n",
    "| Week 10 | 2023.05.03 <br> Data search and exploration  | Selection Topic: <b>Analysis of Disaster Vulnerable Areas<b>    |\n",
    "| Week 11 | 2023.05.10 <br> 문헌조사 |지민 : 논문조사, 김정현 교수님 미팅 <br>  동수 : 논문조사, 김정현 교수님 미팅 , 차별화에 대해 고민  <br> 주찬 : 논문조사 |\n",
    "| Week 12 | 2023.05.17 <br> 산불 취약지역에 대한 조사 |   동수, 지민 : 선행연구 및 사례 조사 <br> 주찬 : 기존 산불취약지도 분석    |\n",
    "| Week 13 | 2023.05.20 <br> 추가 변수 조사 | 동수:소방인프라시설 조사<br>주찬: 도로교통 데이터 조사<br>지민:인구특성 조사        |\n",
    "| Week 14 | 2023.05.27 <br>  방법론 심화 | XGBoost를 중점으로 조사           |\n",
    "| Week 15 | 2023.05.30  <br> Presentation preparation|        |\n",
    "| Week 16 | 2023.06.07  <br> Final presentation|      |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of previous meeting\n",
    "- Previous discussion: 산불 취약지도 및 선행 연구에 대한 조사, 기존 산불 취약 지도 보완점 논의<br>\n",
    "\n",
    "- Comments from Professor: 화재와 산불의 차이가 명확했으면 좋겠다. 로지스틱 회귀분석을 사용할 수 있겠지만 심화된 방법론을 좀 더 고민했으면 좋겠다.<br> \n",
    "\n",
    "- Previous plan:<br> \n",
    " 방법론 심화"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of working progress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [참고 논문 1] 머신러닝과 샘플링을 이용한 강원도 지역 산불발생예측모형 개발\n",
    "\n",
    "산불 피해 면적이 가장 큰 강원도를 중심으로 2003년부터 2016년까지 총 14년의 산불 자료를 이용하였다.<br>\n",
    "기상자료의 오차를 줄이기 위해 강원도를 9개의 구역으로 나누어 각 구역 관측소의 기상자료를 이용하였다.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "      <img src=\"./강원도 구역.png\" width=\"500\" height=\"500\">\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9개의 구역으로 나누어 각 구역의 산불 예측 모형을 만들게 되면 산불이 발생한 날(majority)과 산불이 발생하지 않은 날(minority)의 비율 차이가 큰 불균형 문제가 발생한다.<br>\n",
    "불균형 문제에서는 모델의 성능이 떨어지는 현상이 발생할 수 있다.<br><br>\n",
    "이를 해결하기 위해 여러 샘플링 방법을 적용하였다.<br>- 샘플링X, 언더샘플링 기법,오버샘플링 기법,SMOTE 방법<br><br>\n",
    "모델링 방법은<br>\n",
    "-통계적 방법인 로지스틱 회귀분석 방법과 머신러닝 방법인 random forest와 xgboost 방법을 사용하였다.<br><br>\n",
    "\n",
    "또한 모델의 정확도를 높이기 위해 캐나다 산불 기상 지수(FWI)의 5가지 지수를 파생변수로 사용하였다.<br><br>\n",
    "캐나다 산불 기상지수(Forest fire Weather Index, FWI)에서는 5가지의 지수를 사용하는데 <br>\n",
    "- 평균기온, 평균 습도, 평균풍속, 강수량을 이용하여 계산한다.\n",
    "- 미세 연료 지수(Fine Fuel Moisture Code, FFMC), 부식층지수(Duff moisture code, DMC), 가뭄지수(Drought code, DC)를 1차적으로 계산한 후 이들의 조합으로 ISI(Initial Spread Idex), BUI(Build Up Index)지수를 구한다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "      <img src=\"./결과표.png\" width=\"500\" height=\"300\">\n",
    "</figure>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조사를 통한 아이디어 제시\n",
    "\n",
    "1. 모델링 방법 채택\n",
    "\n",
    "   1.   XGBoost (Extreme Gradient Boosting)\n",
    "-   Tree based algorithm \n",
    "-   Classification task, predictive modelling \n",
    "-   Ensemble learning method (iteratively builds and combines predictions of multiple decision trees) by the boosting method \n",
    "\n",
    "XGBoost is a continuous training algorithm that trains to improve performance on misclassified observations by using more misclassified observations in the next model when generating a tree. It has the advantage of being fast due to parallel computing that uses all CPU cores while training, and it supports a variety of languages, including Python and R, making it highly useful.\n",
    "\n",
    "Advantages \n",
    "1.   Excellent predictive performance\n",
    "2.   Fast running time compared to GBM\n",
    "3.   Overfitting regularization  prevent overfitting and improve generalization of model \n",
    "4.   Built in cross-validation \n",
    "5.   Self-handling of missing values \n",
    "6.   Feature importance -> identify the most relevant feature in dataset\n",
    "     Effectiveness and versatility (regression, binary classification, multi-class classification, and ranking tasks, handle different types of features, such as numerical, categorical, and text data)\n",
    "\n",
    "<Implementation in Python>\n",
    "wildfire/XGBoost Prediction Model.ipynb at main · JamesonThai/wildfire · GitHub\n",
    "wildfire_prediction_demo/main.py at main · DL-WG/wildfire_prediction_demo · GitHub <br>\n",
    "\n",
    "2.   KNN \n",
    "-   supervised learning algorithm \n",
    "-   classification and regression problems\n",
    "-   K-Nearest Neighbors (KNN) algorithm to classify wildfire likelihood based on various features such as temperature, humidity, wind speed, etc. \n",
    "-   Find the k-nearest neighbors to a given data point in the feature space and then classifying the data point based on the majority class of its neighbors\n",
    "\n",
    "KNN python implementation\n",
    "-   GitHub\n",
    "- osyounis/cali_wildfire_likelihood_predictor: General Assembly Data Science Immersive (GA-DSI) Group Project - A machine learning model to predict the likelihood of a California wildfire based on historical weather and wildfire data. <br><br>\n",
    "\n",
    "\n",
    "2. 기존 모델 정확도 향상 <br>\n",
    "[기존 산불취약지도]\n",
    "- 기존 산불취약지도 kernel 집중도함수를 사용하여 예측.\n",
    "- 자세한 방안은 나와있지 않음.\n",
    "<br><br>\n",
    "[화재예측 모델]\n",
    "<br><br>\n",
    "   - 머신러닝을 사용한 화재발생확률, 화재위험지수 예측모형 제안.<br>\n",
    "   - 기상변수와 건물변수를 input data로 활용하여 화재발생확률을 예측함. <br>\n",
    "   - 모형 제작에는 xgboost 패키지를 사용<br>\n",
    "   - 이모형을 통하여 특정 시점의 기상데이터만으로 화재발생확률을 예측가능. <br>\n",
    "   - 예측 대상이 되는 변수: 화재변수(화재발생확률, 재산피해규모)<br>\n",
    "   - 예측에 시용되는 변수: 기상변수, 건물변수(건물 면적, 건물 노후화, 건물밀집도)<br>\n",
    "   - 화재발생여부(1,0)<br>\n",
    "   - 건물 변수(노후화, 면적변수,밀집도)<br>\n",
    "   - 기상변수(평균온도, 평균습도, 평균풍속, 누적강수량 변수)<br>\n",
    "   - (XGBoost) : 학습하는 도중 스스로 변수들의 가중치를 부여하여 튜닝해 나가는 기존의 gradient boosting에 분산/병렬처리를 더한 기계 학습 기법.<br>\n",
    "   - 분산/병렬처리 덕에 빠른 속도로 기계학습이 가능, 앙상블기법을 사용하여 분류에 강점을 지님.<br>\n",
    "   - xgboost의 내장함수 model.feature_importances_()로 변수들이 화재발생확률에 영향을 끼치는 정도(특성중요도)를 확인.<br>\n",
    "   - 특성중요도가 높은 상위 3개 변수를 확인<br>(평균온도, 평균습도, 평균풍향)<br>\n",
    "   - xgbclassfier()함수를 사용해서 화재 발생여부 분류 특성중요도가 높은 변수들(평균온도, 평균습도, 평균풍향)을 위주로 최적의 예측성능을 위해 스스로 변수들의 가중치 튜닝.<br>\n",
    "<br>\n",
    "[Develop]<br>\n",
    "- 산불취약지 예측 모형을 만들때, 지금껏 조사한 데이터들을 xgboost로 적용.<br>\n",
    "- xgbclassifier() 함수를 사용하여, 중요변수 선택후, 중요변수를 가중치를 튜닝.<br>\n",
    "- 화재발생확률 예측모형 Develop 하는 방향.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pending assignments or requests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 모델링 방법 적용\n",
    "2. 모델링 방법 적용 후 정확도 향상 고려"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
